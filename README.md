<h1 align="center">üìä LiftOff Data</h1> 

> Este projeto apresenta uma arquitetura de pipeline de dados de baixo custo, projetada para startups que precisam processar e analisar dados de vendas de forma eficiente.

---

### **Introdu√ß√£o**

Este projeto descreve uma arquitetura de pipeline de dados de baixo custo voltada para startups, com foco em integra√ß√£o de dados de vendas a partir de APIs e CRMs, utilizando tecnologias modernas e acess√≠veis. O objetivo √© criar uma solu√ß√£o escal√°vel para ingest√£o, transforma√ß√£o e visualiza√ß√£o de dados, garantindo que tanto engenheiros de dados quanto analistas possam colaborar eficientemente. A arquitetura proposta inclui a divis√£o do pipeline em m√∫ltiplas camadas (Raw, Bronze, Silver e Gold), integra√ß√£o com APIs, Kafka para streaming, Airbyte para ingest√£o de dados, Airflow para orquestra√ß√£o e DBT para transforma√ß√£o de dados. A plataforma colaborativa "Briefer" tamb√©m √© integrada, permitindo que analistas de dados acessem e utilizem os dados transformados de forma eficiente.

### **Sequence Diagram**

O diagrama abaixo ilustra a intera√ß√£o entre as principais camadas e componentes da arquitetura, desde a ingest√£o dos dados brutos at√© sua transforma√ß√£o e disponibiliza√ß√£o para an√°lise.

```mermaid
sequenceDiagram
    participant U as Usu√°rio
    participant SW as Sistema Web Streamlit
    participant V as Valida√ß√£o Pydantic
    participant DB as Banco de Dados SQLAlchemy
    
    U ->> SW: Inserir Dados
    SW ->> V: Enviar Dados para Valida√ß√£o
    alt Dados V√°lidos
        V ->> DB: Inserir Dados no Banco de Dados
        DB ->> SW: Confirma√ß√£o de Armazenamento
        SW ->> U: Dados Salvos com Sucesso
    else Dados Inv√°lidos
        V ->> SW: Retornar Erros de Valida√ß√£o
        SW ->> U: Exibir Mensagem de Erro
    end
```

---

### **Tecnologias Utilizadas**

#### **Streamlit**

- **Descri√ß√£o:** Streamlit √© uma biblioteca Python de c√≥digo aberto que permite a cria√ß√£o de aplicativos web interativos de forma r√°pida e f√°cil. Utilizado principalmente para construir dashboards e interfaces de dados, o Streamlit √© ideal para prototipagem r√°pida e visualiza√ß√£o de dados sem a necessidade de conhecimentos avan√ßados em desenvolvimento web.
- **Uso no Projeto:** Utilizado para construir o frontend da aplica√ß√£o, permitindo que os usu√°rios insiram dados de vendas de forma interativa e visualizem os resultados diretamente na interface.

#### **Pydantic**

- **Descri√ß√£o:** Pydantic √© uma biblioteca de valida√ß√£o de dados que utiliza modelos baseados em classes Python para garantir que os dados inseridos estejam no formato correto. √â amplamente utilizada para valida√ß√£o e serializa√ß√£o de dados, garantindo integridade e consist√™ncia.
- **Uso no Projeto:** Pydantic √© utilizado para validar os dados inseridos pelos usu√°rios no frontend, garantindo que as informa√ß√µes estejam corretas antes de serem processadas e salvas no banco de dados.

#### **Psycopg2**

- **Descri√ß√£o:** Psycopg2 √© uma biblioteca que permite a intera√ß√£o com bancos de dados PostgreSQL diretamente atrav√©s de Python, facilitando a execu√ß√£o de comandos SQL e o gerenciamento das conex√µes.
- **Uso no Projeto:** Utilizado para conectar a aplica√ß√£o ao banco de dados PostgreSQL, executar comandos SQL, e salvar os dados validados.

#### **SQLAlchemy (Opcional)**

- **Descri√ß√£o:** SQLAlchemy √© uma poderosa biblioteca de SQL toolkit e ORM (Object-Relational Mapping) para Python. Ele permite a intera√ß√£o com bancos de dados relacionais de forma mais intuitiva, utilizando objetos Python em vez de comandos SQL diretamente.
- **Uso no Projeto:** SQLAlchemy poderia ser utilizado para gerenciar a conex√£o com o banco de dados PostgreSQL e facilitar as opera√ß√µes de CRUD (opcional, n√£o implementado no exemplo atual).

#### **MkDocs**

- **Descri√ß√£o:** MkDocs √© uma ferramenta est√°tica de documenta√ß√£o em Python que permite a cria√ß√£o de sites de documenta√ß√£o de forma simples e estruturada. √â especialmente √∫til para projetos que precisam de uma documenta√ß√£o clara e acess√≠vel para os desenvolvedores e usu√°rios.
- **Uso no Projeto:** MkDocs √© utilizado para gerar a documenta√ß√£o do sistema, detalhando como o projeto foi estruturado, as funcionalidades desenvolvidas, e como o sistema deve ser mantido e atualizado.

#### **Airbyte**

- **Descri√ß√£o:** Airbyte √© uma plataforma de integra√ß√£o de dados de c√≥digo aberto que permite conectar facilmente APIs, bancos de dados e outros sistemas para ingest√£o de dados em tempo real.
- **Uso no Projeto:** Respons√°vel pela ingest√£o de dados a partir de diferentes APIs e fontes de dados, garantindo que os dados sejam movidos para as camadas corretas do pipeline.

#### **Kafka**

- **Descri√ß√£o:** Apache Kafka √© uma plataforma de streaming distribu√≠da que permite a publica√ß√£o e assinatura de fluxos de dados em tempo real.
- **Uso no Projeto:** Utilizado para gerenciar o fluxo de dados de maneira escal√°vel e garantir que os dados sejam processados de forma cont√≠nua e eficiente.

#### **Airflow**

- **Descri√ß√£o:** Apache Airflow √© uma plataforma de orquestra√ß√£o de workflows que permite o agendamento e monitoramento de pipelines de dados.
- **Uso no Projeto:** Orquestra a execu√ß√£o de todos os componentes do pipeline, desde a ingest√£o at√© a transforma√ß√£o dos dados.

#### **DBT**

- **Descri√ß√£o:** DBT (Data Build Tool) √© uma ferramenta de transforma√ß√£o de dados que permite a constru√ß√£o de modelos SQL e a aplica√ß√£o de boas pr√°ticas de desenvolvimento de software ao ETL.
- **Uso no Projeto:** Utilizado para transformar os dados das camadas Raw, Bronze e Silver, preparando-os para a camada Gold, onde estar√£o prontos para consumo pelos analistas.

#### **Briefer**

- **Descri√ß√£o:** Briefer √© uma plataforma colaborativa de dados que permite que equipes de analistas acessem, compartilhem e analisem dados de maneira colaborativa.
- **Uso no Projeto:** Facilita o acesso e a explora√ß√£o dos dados transformados pelos analistas, proporcionando um ambiente colaborativo para an√°lise de dados.

---

### **Estrutura do Projeto**

#### **Divis√£o dos M√≥dulos**

O projeto est√° dividido em m√≥dulos para organizar melhor o desenvolvimento e facilitar a manuten√ß√£o futura. A seguir, est√£o os principais m√≥dulos do projeto:

1. **Frontend (`app.py`):**
   - Respons√°vel pela interface do usu√°rio onde os dados de vendas s√£o inseridos e exibidos.
   - Desenvolvido com Streamlit para proporcionar uma intera√ß√£o simples e amig√°vel.

2. **Contrato (`contrato.py`):**
   - Define as regras de valida√ß√£o dos dados utilizando Pydantic.
   - Assegura que os dados inseridos no frontend est√£o no formato correto e cumprem as regras estabelecidas pelo sistema.

3. **Banco de Dados (`database.py`):**
   - Gerencia a conex√£o e as opera√ß√µes com o banco de dados PostgreSQL utilizando Psycopg2.
   - Facilita a intera√ß√£o com o banco sem a necessidade de escrever SQL diretamente.

#### **Divis√£o em Camadas**

O pipeline de dados √© dividido em quatro camadas principais para garantir a qualidade e integridade dos dados √† medida que eles progridem no sistema:

1. **Camada Raw:**
   - Dados brutos, n√£o processados, diretamente das fontes de dados (APIs e CRM).
   
2. **Camada Bronze:**
   - Dados validados e padronizados ap√≥s a ingest√£o, prontos para serem processados.

3. **Camada Silver:**
   - Dados limpos e transformados com regras de neg√≥cio aplicadas.

4. **Camada Gold:**
   - Dados finais prontos para an√°lise e visualiza√ß√£o, acess√≠veis por ferramentas como o Briefer.

---

### **Passos para Configura√ß√£o e Execu√ß√£o**

### **Passos para Configura√ß√£o e Execu√ß√£o**

#### **1. Criar o Reposit√≥rio**

- **Passo:** Inicie um novo reposit√≥rio no GitHub ou GitLab para versionar o projeto.
- **Comando:**
  ```bash
  git init
  ```

#### **2. Escolher a Vers√£o do Python para 3.12.3**

- Utilize `pyenv` para gerenciar e definir a vers√£o correta do Python:
  ```bash
  pyenv install 3.12.3
  pyenv local 3.12.3
  ```

#### **3. Criar um Ambiente Virtual**

- **Passo:** Crie um ambiente virtual para isolar as depend√™ncias do projeto.
- **Comando:**
  ```bash
  python3.12 -m venv .venv
  ```

#### **4. Entrar no Ambiente Virtual**

- **Comando:**
  - **Windows:**
    ```bash
    .venv\Scripts\activate
    ```
  - **Linux/Mac:**
    ```bash
    source .venv/bin/activate
    ```

#### **5. Instalar as Depend√™ncias**

- **Instalar os pacotes necess√°rios:**
  ```bash
  pip install -r requirements.txt
  ```

#### **6. Executar o Frontend**

- **Comando para rodar o frontend com Streamlit:**
  ```bash
  streamlit run app.py
  ```

#### **7. Configurar o PostgreSQL**

- **Criar o banco de dados e a tabela necess√°ria:**
  ```sql
  CREATE DATABASE crm_vendas;
  CREATE TABLE vendas (
      id SERIAL PRIMARY KEY,
      email VARCHAR(255) NOT NULL,
      data TIMESTAMP NOT NULL,
      valor NUMERIC NOT NULL,
      quantidade INTEGER NOT NULL,
      produto VARCHAR(50) NOT NULL
  );
  ```

#### **8. Criar a Conex√£o com o PostgreSQL**

- A conex√£o √© gerenciada no m√≥dulo `database.py` utilizando `psycopg2`.

### **Conclus√£o**

Este projeto de arquitetura de pipeline de dados para startups oferece uma solu√ß√£o eficiente, escal√°vel e de baixo custo para lidar com o processamento e an√°lise de grandes volumes de dados de vendas. Com a utiliza√ß√£o de ferramentas modernas como Airbyte, Kafka, Airflow, DBT e Briefer, o pipeline garante a ingest√£o, transforma√ß√£o e disponibiliza√ß√£o dos dados em camadas organizadas (Raw, Bronze, Silver, Gold), permitindo uma an√°lise colaborativa e em tempo real.

Essa arquitetura modular e flex√≠vel facilita a adapta√ß√£o e o crescimento conforme a demanda aumenta, tornando-se uma excelente escolha para startups que precisam otimizar seus processos de dados sem comprometer o or√ßamento.